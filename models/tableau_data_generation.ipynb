{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "import datetime\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2821: DtypeWarning: Columns (5,6,7,8,11,12,13,14,17,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n",
      "/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2821: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "visitors, events, devices, url_categories = utils.load_data(event_categories=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_quarters(dt):\n",
    "    if dt < datetime.date(2017, 5, 1):\n",
    "        return 'q1'\n",
    "    elif dt < datetime.date(2017, 8, 1):\n",
    "        return 'q2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "specialties = visitors.groupby('primary_specialty').npi_number.count().sort_values(ascending=False).reset_index()\n",
    "total = specialties.npi_number.sum()\n",
    "specialties['pct'] = specialties.npi_number.apply(lambda x: x/total)\n",
    "specialties.to_csv('../data/specialty_breakdown.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session Level Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_use_case(events, three=True):\n",
    "    if three:\n",
    "        publisher_tools = ['Publisher', 'Reference Tool', 'Medical Education', 'Multi-Channel Marketing']\n",
    "        pharma = ['Pharma', 'Med Device']\n",
    "        social = ['Professional Social', 'Medical Association', 'Recruiter']\n",
    "\n",
    "        events['use_case'] = ''\n",
    "        events.loc[events.site_category.isin(publisher_tools), 'use_case'] = 'publications_ed_tools'\n",
    "        events.loc[events.site_category.isin(pharma), 'use_case'] = 'pharma_device'\n",
    "        events.loc[events.site_category.isin(social), 'use_case'] = 'professional_social_media'\n",
    "        events.loc[events.use_case=='', 'use_case'] = 'other'\n",
    "    else:\n",
    "        use_cases = {\n",
    "            'publication_research' : ['Publisher'],\n",
    "            'education_tools' : ['Reference Tool', 'Medical Education', 'Multi-Channel Marketing'],\n",
    "            'pharma' : ['Pharma', 'Med Device'],\n",
    "            'social_professional' : ['Professional Social', 'Medical Association', 'Recruiter']\n",
    "        }\n",
    "\n",
    "        for u in use_cases:\n",
    "            events.loc[events.site_category.isin(use_cases[u]), 'use_case'] = u\n",
    "        events.loc[events.use_case=='', 'use_case'] = 'other'\n",
    "    return events\n",
    "\n",
    "def aggregate_sessions(events, output_file=None, use_case_truncated=False):\n",
    "    ev = get_use_case(events, three=use_case_truncated)\n",
    "    ev['quarter'] = ev.timestamp.apply(lambda x: get_quarters(x.date()))\n",
    "    sessions = ev.groupby('session_id').event_id.count().reset_index()\n",
    "    sessions = sessions.rename(columns={'event_id':'page_views'})\n",
    "    event_sessions = events.drop_duplicates('session_id')\n",
    "    event_sessions = pd.merge(event_sessions, sessions, on='session_id')\n",
    "    event_sessions = pd.merge(visitors, event_sessions, on='dg_id')\n",
    "    \n",
    "    if output_file:\n",
    "        tableau_sessions = event_sessions[['timestamp', 'dg_id', 'npi_number', 'primary_specialty', 'site_category', 'site_sub_category', 'disease_category', 'disease', 'pharma_firm', 'use_case', 'page_views']]\n",
    "        tableau_sessions.to_csv(output_file, index=False)\n",
    "    else:\n",
    "        return event_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "event_sessions = aggregate_sessions(events, use_case_truncated=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Personas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# https://en.wikipedia.org/wiki/Ternary_plot\n",
    "    \n",
    "def to_cartesian(a,b,c):\n",
    "    x = .5*(2*b+c)/(a+b+c)\n",
    "    y = (np.sqrt(3)/2)*(c/(a+b+c))\n",
    "    return (x,y)\n",
    "\n",
    "def get_persona(x,y):\n",
    "    if y > np.sqrt(3)/4:\n",
    "        return 'butterfly'\n",
    "    elif y + np.sqrt(3)*x <= np.sqrt(3)/2:\n",
    "        return 'unicorn'\n",
    "    elif np.sqrt(3)*x - y >= np.sqrt(3)/2:\n",
    "        return 'bookworm'\n",
    "    else:\n",
    "        return 'cat?'\n",
    "    \n",
    "def get_personas(event_sessions):\n",
    "    personas = event_sessions.groupby('dg_id').use_case.apply(list).reset_index()\n",
    "    personas = pd.merge(personas, visitors[['dg_id', 'primary_specialty']], on='dg_id')\n",
    "    personas['total_sessions'] = personas.use_case.apply(lambda x: len(x))\n",
    "    personas['use_case_counts'] = personas.use_case.apply(lambda x: Counter(x))\n",
    "    \n",
    "    # parse out use case counts\n",
    "    personas['pharma'] = personas.use_case_counts.apply(lambda x: x['pharma_device'])\n",
    "    personas['publications'] = personas.use_case_counts.apply(lambda x: x['publications_ed_tools'])\n",
    "    personas['social'] = personas.use_case_counts.apply(lambda x: x['professional_social_media'])\n",
    "    personas['total_3d'] = personas.apply(lambda x: x.pharma + x.publications + x.social, axis=1)\n",
    "    \n",
    "    # exclude folks with only 'other' category (will address eventually)\n",
    "    personas = personas[personas.total_3d > 0]\n",
    "    \n",
    "    # normalize per user\n",
    "    personas['pharma_pct'] = personas.apply(lambda x: x.pharma/x.total_3d, axis=1)\n",
    "    personas['pubs_pct'] = personas.apply(lambda x: x.publications/x.total_3d, axis=1)\n",
    "    personas['social_pct'] = personas.apply(lambda x: x.social/x.total_3d, axis=1)\n",
    "    \n",
    "    # get coordinates to define persona\n",
    "    personas['ternary_coordinates'] = personas.apply(lambda x: to_cartesian(x.pharma_pct, x.pubs_pct, x.social_pct), axis=1)\n",
    "    personas['persona'] = personas.ternary_coordinates.apply(lambda x: get_persona(x[0], x[1]))\n",
    "    \n",
    "    return personas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "personas = get_personas(event_sessions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NPI Level Summary Statitsics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def categorize_frequency(n):\n",
    "    if n < 1:\n",
    "        return 'Less than 1 visit a month' \n",
    "    elif n <= 10:\n",
    "        return '1-10 times per month'\n",
    "    else:\n",
    "        return 'More than 10x per month'\n",
    "    \n",
    "def npi_level_summary_statistics(output_file=None, npis=None, personas=False):\n",
    "    # if given a list of users, pull in those. otherwise, use all available data\n",
    "    if npis:\n",
    "        v = visitors[visitors.npi_number.isin(npis)]\n",
    "    else:\n",
    "        v = visitors[visitors.exclude==0]\n",
    "    ev = pd.merge(v, events, on='dg_id')\n",
    "    if len(ev) == 0:\n",
    "        print 'target list has no web activity'\n",
    "        return\n",
    "    # check which users have web activity\n",
    "    event_dgids = set(ev.dg_id)\n",
    "    v['has_event'] = v.dg_id.apply(lambda x: 1 if x in event_dgids else 0)\n",
    "    \n",
    "    # check frequency of web activity (timeframe denominator starts with the earliest date the user has activity)\n",
    "    max_dt = max(events.timestamp).date()\n",
    "    ev['dt'] = ev.timestamp.apply(lambda x: x.date())\n",
    "    ev['quarter'] = ev.dt.apply(lambda x: get_quarters(x))\n",
    "    freq = ev.drop_duplicates(subset=['dg_id', 'dt']).groupby(['dg_id']).dt.agg(['min', 'max', 'count']).reset_index()\n",
    "    freq['sessions_per_month'] = freq.apply(lambda x: x['count']/(max(1, (max_dt-x['min']).days)/30), axis=1)\n",
    "    freq['frequency_category'] = freq.sessions_per_month.apply(lambda x: categorize_frequency(x))\n",
    "    v = pd.merge(v, freq[['dg_id', 'sessions_per_month', 'frequency_category']], how='left')\n",
    "    \n",
    "    # separate frequency by quarter\n",
    "    freqq = ev.drop_duplicates(subset=['dg_id', 'dt']).groupby(['dg_id', 'quarter']).dt.agg(['min', 'max', 'count']).reset_index()\n",
    "    freqq['sessions_per_month'] = freqq.apply(lambda x: x['count']/(max(1, (max_dt-x['min']).days)/30), axis=1)\n",
    "    freqq['frequency_category'] = freqq.sessions_per_month.apply(lambda x: categorize_frequency(x))\n",
    "    freqq = freqq.pivot(index='dg_id', columns='quarter', values='frequency_category').reset_index()\n",
    "    freqq.columns= ['dg_id', 'frequency_category_q1', 'frequency_category_q2']\n",
    "    v = pd.merge(v, freqq, on='dg_id', how='left')\n",
    "    \n",
    "    # grab avg number of urls per session\n",
    "    urls_per_session = ev.groupby(['dg_id', 'session_id']).url.nunique().reset_index()\\\n",
    "        .groupby('dg_id').url.mean().reset_index()\n",
    "    urls_per_session = urls_per_session.rename(columns={'url':'urls_per_session'})\n",
    "    v = pd.merge(v, urls_per_session, on='dg_id', how='left')\n",
    "    \n",
    "    tableau_columns = [\n",
    "        'dg_id', \n",
    "        'identity_type', \n",
    "        'professional_designation', \n",
    "        'npi_number', \n",
    "        'primary_specialty', \n",
    "        'primary_specialty_group', \n",
    "        'birth_year', \n",
    "        'grad_year', \n",
    "        'gender', \n",
    "        'has_event', \n",
    "        'sessions_per_month', \n",
    "        'frequency_category',\n",
    "        'frequency_category_q1',\n",
    "        'frequency_category_q2',\n",
    "        'urls_per_session' \n",
    "    ]\n",
    "        \n",
    "    if personas:\n",
    "        event_sessions = aggregate_sessions(ev, use_case_truncated=True)\n",
    "        personas = get_personas(event_sessions)\n",
    "        v = pd.merge(v, personas[['dg_id', 'persona']], on='dg_id', how='left')\n",
    "        tableau_columns.append('persona')\n",
    "        \n",
    "    if output_file:\n",
    "        v[tableau_columns].to_csv(output_file, index=False)\n",
    "    else:\n",
    "        return v[tableau_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# generate new sample of NPIs for dashboard\n",
    "npis = list(visitors[(~visitors.npi_number.isnull())\\\n",
    "                     &(visitors.professional_designation=='Physician')\\\n",
    "                     &(visitors.exclude==0)]\\\n",
    "            .sample(10000).npi_number)\n",
    "\n",
    "npi_level_summary_statistics(output_file='../data/npi_sample_with_personas_20170815.csv', npis=npis, personas=True)\n",
    "#df = npi_level_summary_statistics(npis=npis, personas=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bookworm     543\n",
       "unicorn       50\n",
       "butterfly     28\n",
       "cat?           2\n",
       "Name: persona, dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[~df.persona.isnull()].persona.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
